{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "421it [00:00, 9585.86it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering paths...\n",
      "Done !\n",
      "Dataset size: 421 subjects\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "421it [15:29,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchio as tio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "\n",
    "# path to ct scans\n",
    "image_paths = sorted(glob.glob(\"../data/preprocessed/img/*.nii\"))\n",
    "\n",
    "# path to primary tumor's masks\n",
    "label_paths = sorted(glob.glob('../data/preprocessed/seg/*GTV*.nii'))\n",
    "\n",
    "df = pd.read_csv(\"../data/lung-01.csv\")\n",
    "\n",
    "# Preprocessing operations\n",
    "trans = tio.Compose([\n",
    "    tio.ToCanonical(),\n",
    "    tio.Resample(\"gtv\"),\n",
    "    tio.Resample(1),\n",
    "    tio.CropOrPad((220,120,60), mask_name='gtv'),\n",
    "    tio.ZNormalization(masking_method=tio.ZNormalization.mean),\n",
    "])\n",
    "\n",
    "subjects = []\n",
    "indexs = []\n",
    "\n",
    "print(\"Gathering paths...\")\n",
    "for (image_path, label_path) in tqdm(zip(image_paths, label_paths)):\n",
    "    \n",
    "    subject = tio.Subject(\n",
    "        ctscan=tio.ScalarImage(image_path),\n",
    "        gtv=tio.LabelMap(label_path),\n",
    "    )\n",
    "    subjects.append(subject)\n",
    "    indexs.append(image_path[-13:-4])\n",
    "\n",
    "dataset = tio.SubjectsDataset(subjects)\n",
    "\n",
    "print(\"Done !\")\n",
    "\n",
    "print('Dataset size:', len(dataset), 'subjects')\n",
    "\n",
    "print(\"Creating dataset...\")\n",
    "for i, subject in tqdm(zip(indexs, dataset)):\n",
    "    if int(i[-3:]) < 144:\n",
    "        continue\n",
    "    \n",
    "    survival_time = df.iloc[int(i[6:])-1][\"Survival.time\"]\n",
    "    status_event = df.iloc[int(i[6:])-1][\"deadstatus.event\"]\n",
    "    \n",
    "    subject = trans(subject)\n",
    "    t = subject.ctscan.data.squeeze().detach().numpy()\n",
    "    m = subject.gtv.data.squeeze().detach().numpy()\n",
    "\n",
    "    np.save(\"../data/dataset/\"+i, np.array([t, m, survival_time, status_event], dtype=object))\n",
    "\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07429fcb4c504a0378980367d3c7fce80391802e4a36d1633a5a7bb6cd53a327"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
